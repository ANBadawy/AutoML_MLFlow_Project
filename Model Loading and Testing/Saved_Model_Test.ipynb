{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing The Required Packages"
      ],
      "metadata": {
        "id": "x0oHFJnHFfcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers accelerate bitsandbytes peft huggingface_hub\n",
        "!pip install --upgrade transformers accelerate bitsandbytes peft huggingface_hub\n",
        "!pip install ipywidgets --upgrade\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T17:32:01.663134Z",
          "iopub.execute_input": "2024-11-16T17:32:01.663792Z",
          "iopub.status.idle": "2024-11-16T17:33:04.790008Z",
          "shell.execute_reply.started": "2024-11-16T17:32:01.663749Z",
          "shell.execute_reply": "2024-11-16T17:33:04.78896Z"
        },
        "id": "KWVeitWnFfcT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loader"
      ],
      "metadata": {
        "id": "CiCJ1NMbFfcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the PEFT configuration\n",
        "peft_model_id = 'alinasser930/unsloth-mistral-tuned_model'\n",
        "\n",
        "peft_config = PeftConfig.from_pretrained(\n",
        "    peft_model_id,\n",
        ")\n",
        "base_model_name = peft_config.base_model_name_or_path\n",
        "\n",
        "print(f\"Base model: {base_model_name}\")\n",
        "\n",
        "# Load the base model and tokenizer\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_name,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    trust_remote_code=True,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "# Load the LoRA adapter\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    peft_model_id,\n",
        "    trust_remote_code=True,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "# Prepare for inference\n",
        "model.eval()\n",
        "\n",
        "\n",
        "test_prompt = \"\"\"Given the following description of time series data, identify the single best fitting machine learning algorithm from the provided list. Do not include any explanation, and only provide the algorithm's name.\n",
        "\n",
        "Available algorithms: AdaboostClassifier, ElasticNetClassifier, LassoClassifier, LightgbmClassifier, SVC, GaussianProcessClassifier, RandomForestClassifier, XGBoostClassifier.\n",
        "\n",
        "### DESCRIPTION:\n",
        "\n",
        "{}\n",
        "\n",
        "### ALGORITHM:\n",
        "\"\"\"\n",
        "\n",
        "description = \"A multivariate classification time-series dataset consists of 7606 samples and 16 features with 16 numerical and 0 categorical features. Each instance has a window length of 24. The dataset has a sampling rate of 60.0 minutes. The dataset has a missing values percentage of 0.0%. The missing values percentages for numerical features range from 0 to 0 with mean 0.00 and standard deviation 0.00.\\n The target column has 3 classes with entropy value 1.47 showing a Unbalanced dataset. Among the 7606 samples the target ground-truth class has changed 1618 times representing a percentage of 21.37%. There are 16 features in the dataset\\n Among the numerical predictors, the series has 16 numerical features detected as Stationary out of the 16 numerical features using the dickey-fuller test and the rest are Unstationary. 15 of them are Multiplicative time-series features and the rest are Additive time-series features. There is an average of 0 seasonality components detected in the numerical predictors. The top 0 common seasonality components are represented using sinusoidal waves. The numerical predictors also exhibit skewness values ranging from 0.011. to 15.884 and kurtosis values of 0.00 to 321.97. The fractal dimension analysis yields values ranging from -0.66 to -0.11 indicating a Complex and Irregular time-series structure for the numerical predictors. The correlation values among the numerical predictors have a minimum of -0.95, maximum 1.00, mean 0.10, and standard deviation 0.48. The count of numerical predictors with outliers is 15 with the minimum percentage of 0.00%, maximum percentage of 14.41%, average percentage of 5.89%, and standard deviation percentage of 4.64%.\\n\\nThe dataset is converted into a simple classification task by extracting the previously described features.\"\n",
        "\n",
        "\n",
        "# Format the prompt with the description\n",
        "formatted_prompt = test_prompt.format(description)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(\n",
        "    formatted_prompt,\n",
        "    return_tensors='pt'\n",
        ").to(model.device)\n",
        "\n",
        "# Generate the output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_new_tokens=10,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T17:33:04.792034Z",
          "iopub.execute_input": "2024-11-16T17:33:04.792362Z",
          "iopub.status.idle": "2024-11-16T17:35:58.157477Z",
          "shell.execute_reply.started": "2024-11-16T17:33:04.792325Z",
          "shell.execute_reply": "2024-11-16T17:35:58.156626Z"
        },
        "id": "Y3fDlkasFfcU",
        "outputId": "03687197-8366-4bcc-d6ef-877675755736",
        "colab": {
          "referenced_widgets": [
            "025473b695b44082bf9c6fd7919f57be",
            "3c973c34b38f4ce4913ddf123da77150",
            "7b8fe3a0e5fe4d2b93796d7ac4e6ee3a",
            "4807e3f7e86b4772bcd1b9d6a0fef5aa",
            "ebdb15c27f65413d9f75198e626bd00a",
            "2d509ac9f6cf476a8163948a1b2b09c6",
            "b64c10b59b3b4b719c44d659ae8c8865",
            "e852b54d36b24ad4b941c72202190304",
            "80d06b511ee24d89b519f53443c537ed"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "025473b695b44082bf9c6fd7919f57be"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Base model: unsloth/mistral-7b-instruct-v0.2-bnb-4bit\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c973c34b38f4ce4913ddf123da77150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b8fe3a0e5fe4d2b93796d7ac4e6ee3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4807e3f7e86b4772bcd1b9d6a0fef5aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebdb15c27f65413d9f75198e626bd00a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d509ac9f6cf476a8163948a1b2b09c6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b64c10b59b3b4b719c44d659ae8c8865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e852b54d36b24ad4b941c72202190304"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80d06b511ee24d89b519f53443c537ed"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Output"
      ],
      "metadata": {
        "id": "V7NqBFS3FfcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode and display the response\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "response_text = response.split('### ALGORITHM:')[-1].strip()\n",
        "\n",
        "# List of algorithms\n",
        "algorithms = [\n",
        "    'AdaboostClassifier',\n",
        "    'ElasticNetClassifier',\n",
        "    'LassoClassifier',\n",
        "    'LightgbmClassifier',\n",
        "    'SVC',\n",
        "    'GaussianProcessClassifier',\n",
        "    'RandomForestClassifier',\n",
        "    'XGBoostClassifier',\n",
        "]\n",
        "\n",
        "# Extract the algorithm name\n",
        "selected_algorithm = None\n",
        "for algo in algorithms:\n",
        "    if algo.lower() in response_text.lower():\n",
        "        selected_algorithm = algo\n",
        "        break\n",
        "\n",
        "if selected_algorithm:\n",
        "     print(f\"The Best Alogrithm for This description is: {selected_algorithm}\")\n",
        "else:\n",
        "    print(\"No algorithm found in the response.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T17:35:58.158748Z",
          "iopub.execute_input": "2024-11-16T17:35:58.159324Z",
          "iopub.status.idle": "2024-11-16T17:35:58.167189Z",
          "shell.execute_reply.started": "2024-11-16T17:35:58.159269Z",
          "shell.execute_reply": "2024-11-16T17:35:58.166356Z"
        },
        "id": "hSVK2RCQFfcU",
        "outputId": "d2db981b-cd61-4875-871e-f3c12329e181"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The Best Alogrithm for This description is: AdaboostClassifier\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}